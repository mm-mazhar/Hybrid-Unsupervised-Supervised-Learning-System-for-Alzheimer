{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40cb4b04-b275-4454-ab1f-838fcb41075c",
   "metadata": {},
   "source": [
    "#### Mount G Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9289be-9e77-4895-9d5d-192ea7316f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d301ddc-a49d-4e92-8d61-31bc2274cc6e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f0d3187-763a-47f9-9501-727c55782057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Dir >>> C:\\Users\\maz\\dev\\Projects_\\alzheimer\n",
      "Current Working Dir >>> C:\\Users\\maz\\dev\\Projects_\\alzheimer\\research\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "# warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pprint\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch # Used to check for GPU availability\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# Custom Functions\n",
    "from utils import *\n",
    "\n",
    "# print(f\"Current Working Directory --> {os.getcwd()}\")\n",
    "#Add one directory above research\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\")) # Get the parent directory\n",
    "sys.path.append(parent_dir)\n",
    "current_working_dir = %pwd\n",
    "\n",
    "print(f\"Parent Dir >>> {parent_dir}\")\n",
    "print(f\"Current Working Dir >>> {current_working_dir}\")\n",
    "\n",
    "# from configs import cfgs  # Absolute import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6665ccf-5b5f-48e1-96be-e83ba57b4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74223f-66b2-402d-af7b-e08411349b06",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce61f911-9652-4b69-8f94-ae40a526239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path\n",
      "************\n",
      "Dataset: ..\\dataset\\modified\n",
      "Train File Path --> ..\\dataset\\modified\\train.csv\n",
      "\n",
      "\n",
      "Model's Dir\n",
      "************\n",
      "Models Dir: ..\\models\n",
      "Model's Save Path --> ..\\models\\ft_engineered\n"
     ]
    }
   ],
   "source": [
    "# Create a path object\n",
    "# dataset_dir = cfgs[\"DATASET_DIR\"]\n",
    "dataset_dir = \"..//dataset//modified\"\n",
    "dataset_path = Path(dataset_dir)\n",
    "print(\"Dataset Path\")\n",
    "print(\"*\"*12)\n",
    "print(f\"Dataset: {dataset_path}\")\n",
    "\n",
    "path_train = dataset_path / \"train.csv\"\n",
    "print(f\"Train File Path --> {path_train}\")\n",
    "\n",
    "# # Path to save Splits\n",
    "# split_train_csv = dataset_path / 'ag_train.csv'\n",
    "# split_test_csv = dataset_path / 'ag_test.csv'\n",
    "\n",
    "# print(f\"Train Split File Path --> {split_train_csv}\")\n",
    "# print(f\"Test Split File Path --> {split_test_csv}\")\n",
    "\n",
    "# Define the path to save the trained models\n",
    "models_dir = \"..//models//\"\n",
    "models_path = Path(models_dir)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Model's Dir\")\n",
    "print(\"*\"*12)\n",
    "print(f\"Models Dir: {models_path}\")\n",
    "\n",
    "model_name = 'ft_engineered'\n",
    "model_save_path = models_path / model_name\n",
    "\n",
    "try:\n",
    "    os.makedirs(model_save_path)\n",
    "    print(f\"Directory '{model_save_path}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{model_save_path}' already exists.\")\n",
    "    \n",
    "print(f\"Model's Save Path --> {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5789c4-5868-4021-8708-e66a1e98dddc",
   "metadata": {},
   "source": [
    "#### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b359b5-35f6-4540-a009-3c33a2120c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "label_column = 'composite_score'\n",
    "\n",
    "SPECIFIC_COL_TO_DROP = ['Year']\n",
    "\n",
    "THRESHOLD_RATIO = 0.1\n",
    "MAX_UNIQUE = 50\n",
    "\n",
    "# These are rudundant features\n",
    "COLS_TO_DROP = ['UID', 'imss_03', 'imss_12', 'issste_03', 'issste_12', 'pem_def_mar_03', 'pem_def_mar_12',\n",
    "                   'insur_private_03', 'insur_private_12', 'insur_other_03', 'insur_other_12', 'seg_pop_12',\n",
    "                   'Tired_03', 'Tired_12', 'Happy_03', 'Happy_12']\n",
    "\n",
    "COLS_TO_DROP_AFTER_FT_ENG = ['delta_hinc_business', 'delta_hinc_cap']\n",
    "\n",
    "THRESHOLD_MISSING = 70.0\n",
    "\n",
    "NUM_STRATEGY = \"median\"\n",
    "CAT_STRATEGY = \"mode\"\n",
    "\n",
    "THRESHOLD_QUASI_CONSTANT = 0.00000001 # 0.01 (drops -> cols: 23), 0.005 (drops -> cols: 18), 0.00000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa361044-af0d-4af1-a294-9f4b86beabda",
   "metadata": {},
   "source": [
    "#### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77725850-4354-4360-adc5-97894195c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPUs for training.\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "num_gpus = 1 if torch.cuda.is_available() else 0\n",
    "print(f\"Using {num_gpus} GPUs for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9469a-a2b2-4db7-9047-8329dd85caed",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b5c78c-7630-47e1-a8da-b76696552f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Year</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>Age_03</th>\n",
       "      <th>Urban_03</th>\n",
       "      <th>Married_03</th>\n",
       "      <th>Marriages_03</th>\n",
       "      <th>Education_03</th>\n",
       "      <th>Num_Living_Child_03</th>\n",
       "      <th>Migration_03</th>\n",
       "      <th>...</th>\n",
       "      <th>Meet_FnF_12</th>\n",
       "      <th>SocialActivities_12</th>\n",
       "      <th>AttendReligiousServices_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>YrsLivedInUSA_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>SpeaksEnglish_12</th>\n",
       "      <th>HousingEnvironment_12</th>\n",
       "      <th>PredictionYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aard</td>\n",
       "      <td>2021</td>\n",
       "      <td>104</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7-9 Years</td>\n",
       "      <td>1 or 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Once a week</td>\n",
       "      <td>Never</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abme</td>\n",
       "      <td>2021</td>\n",
       "      <td>106</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Married or In Civil Union</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-5 Years</td>\n",
       "      <td>5 or 6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Never</td>\n",
       "      <td>Never</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    UID  Year  composite_score Age_03 Urban_03                 Married_03  \\\n",
       "0  aard  2021              104  50-59    Urban                    Widowed   \n",
       "1  abme  2021              106  50-59    Rural  Married or In Civil Union   \n",
       "\n",
       "   Marriages_03 Education_03 Num_Living_Child_03  Migration_03  ...  \\\n",
       "0           1.0    7-9 Years              1 or 2           0.0  ...   \n",
       "1           1.0    1-5 Years              5 or 6           0.0  ...   \n",
       "\n",
       "   Meet_FnF_12  SocialActivities_12  AttendReligiousServices_12  a16a_12  \\\n",
       "0  Once a week                Never                         1.0      NaN   \n",
       "1        Never                Never                         0.0      NaN   \n",
       "\n",
       "   YrsLivedInUSA_12  a22_12  a33b_12  SpeaksEnglish_12  HousingEnvironment_12  \\\n",
       "0               NaN     NaN      NaN               0.0               Concrete   \n",
       "1               NaN     NaN      NaN               0.0               Concrete   \n",
       "\n",
       "   PredictionYear  \n",
       "0               9  \n",
       "1               9  \n",
       "\n",
       "[2 rows x 185 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2889, 185)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv(path_train, encoding = 'utf8')\n",
    "    df = data.copy()\n",
    "    display(df.head(2))\n",
    "    print(df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train_with_featEng.csv' not found. Please ensure the file is in the correct location.\")\n",
    "    df = None\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad699607-6a32-4117-8ec2-981ab6a2f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"*\" * 30)\n",
    "# print(\"After Conversion of Data Types\")\n",
    "# print(\"*\" * 30)\n",
    "# # Get all dtypes as a Series\n",
    "# all_dtypes = df.dtypes\n",
    "# print(\"-\" * 20)\n",
    "# print(\"All dtypes (Series):\")\n",
    "# print(\"-\" * 20)\n",
    "# print(f\"All Data Types -> {all_dtypes}\")\n",
    "\n",
    "# # Get unique dtypes\n",
    "# unique_dtypes = df.dtypes.unique()\n",
    "# print(\"-\" * 45)\n",
    "# print(\"Unique dtypes (NumPy array of dtype objects):\")\n",
    "# print(\"-\" * 45)\n",
    "# print(f\"Unique Data Types -> {unique_dtypes}\")\n",
    "\n",
    "# # Get Columns Names\n",
    "# print(\"-\" * 14)\n",
    "# print(\"Column Names:\")\n",
    "# print(\"-\" * 14)\n",
    "# print(f\"{df.columns}\")\n",
    "\n",
    "# print(\"-\" * 18)\n",
    "# print(\"Number of Columns:\")\n",
    "# print(\"-\" * 18)\n",
    "# number_of_cols = len(df.columns)\n",
    "# print(f\"{number_of_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f64f6-c13d-4c7e-9916-5993a2ee7144",
   "metadata": {},
   "source": [
    "#### PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fd02696-16d3-43ff-b6ee-eabec9371cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_conversion = Pipeline([\n",
    "    ('specific_categorizer', SpecificColumnCategorizer(columns_to_categorize=SPECIFIC_COL_TO_DROP)),\n",
    "    ('object_to_category', ObjectToCategoryTransformer(threshold_ratio=THRESHOLD_RATIO, max_unique=MAX_UNIQUE)),\n",
    "    ('float_to_category', FloatToCategoryTransformer()),\n",
    "    # ('bool_to_category', BooleanToCategoryTransformer())    \n",
    "])\n",
    "\n",
    "dropColumns = Pipeline([\n",
    "    ('drop_columns', ColumnDropper(columns_to_drop=COLS_TO_DROP)),\n",
    "])\n",
    "\n",
    "dropColumnsHighNA = Pipeline([\n",
    "    ('drop_columns_high_na', DropColumnsHighNA(threshold=THRESHOLD_MISSING)),\n",
    "])\n",
    "\n",
    "missingValueImputer = Pipeline([\n",
    "    ('missing_value_imputer', MissingValueImputer(num_strategy=NUM_STRATEGY, cat_strategy=CAT_STRATEGY)),\n",
    "])\n",
    "\n",
    "identifyAndDropLowVarNum = Pipeline([\n",
    "    ('identify_and_drop_low_var_num', IdentifyAndDropLowVarNum(quasi_constant_threshold=THRESHOLD_QUASI_CONSTANT)),\n",
    "])\n",
    "\n",
    "# Create a transformer step from your custom function\n",
    "temporal_feature_engineering = Pipeline([\n",
    "    ('temporal_features', FunctionTransformer(engineer_temporal_features, kw_args={'drop_originals': True}))\n",
    "])\n",
    "\n",
    "dropColumns_after_ft_eng = Pipeline([\n",
    "    ('drop_columns', ColumnDropper(columns_to_drop=COLS_TO_DROP_AFTER_FT_ENG)),\n",
    "])\n",
    "\n",
    "dataPreprocessing_pipeline = Pipeline([\n",
    "    ('1_data_type_conversion', data_type_conversion),\n",
    "    ('2_drop_columns', dropColumns),\n",
    "    ('3_drop_high_na_columns', dropColumnsHighNA),\n",
    "    ('4_impute_missing_values', missingValueImputer),\n",
    "    ('5_identify_and_drop_low_var_num', identifyAndDropLowVarNum),\n",
    "    # You can add more steps here, e.g., scaling, encoding, etc.\n",
    "    # ('5_scaling', StandardScaler()), # Example\n",
    "    ('6_temporal_feature_engineering', temporal_feature_engineering),\n",
    "    ('7_dropColumns_after_ft_eng', dropColumns_after_ft_eng),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0de9e0a-da79-46a5-911a-0ec8213fc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"*\" * 48)\n",
    "print(\"--- Applying Pipeline | Data Preprocessing ---\")\n",
    "print(\"*\" * 48, \"\\n\")\n",
    "\n",
    "df = dataPreprocessing_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4661ed95-fbbc-499c-b04d-d66d4bb8eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PipeLine Completed ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- PipeLine Completed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b248a30-fc2f-4d3d-8f94-3b6390b4a6ae",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ac2973-1bda-4610-b8f6-6e17bc4ec204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data size: 2311\n",
      "Test data size: 578\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "# Save the split data to files (optional, but good practice)\n",
    "# train_data.to_csv(split_train_csv, index=False)\n",
    "# test_data.to_csv(split_test_csv, index=False)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(f\"Split | 'Train' | Saved to >>> {split_train_csv}\")\n",
    "# print(f\"Split | 'Test' | Saved to >>> {split_test_csv}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "print(\"Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3ad8a-2d71-42d8-9b19-a7daf1f8ceba",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa78dc74-9bea-4a16-891c-22e871accb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `num_gpus` argument controls GPU usage.\n",
    "# - Set to 1 (or more) to train on GPU.\n",
    "# - Set to 0 to train on CPU only.\n",
    "\n",
    "fit_args = {\n",
    "    'train_data': train_data,\n",
    "    'presets': 'extreme_quality',\n",
    "    'time_limit': 3600,  # Time limit in seconds (e.g., 1 hour)\n",
    "    'num_gpus': num_gpus,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e6c4a0d-89b9-48a4-96e4-fd33b3048c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"..\\models\\ft_engineered\"\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TabularPredictor\n",
    "predictor = TabularPredictor(\n",
    "    label=label_column,\n",
    "    path=model_save_path,\n",
    "    eval_metric='root_mean_squared_error' # Default for regression, but explicitly stated for clarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e6c3eb4-21b4-40f6-8894-dd17f85705ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       3.85 GB / 19.90 GB (19.3%)\n",
      "Disk Space Avail:   233.44 GB / 953.87 GB (24.5%)\n",
      "===================================================\n",
      "Presets specified: ['extreme_quality']\n",
      "`extreme` preset uses a dynamic portfolio based on dataset size...\n",
      "\tDetected data size: small (<=30000 samples), using `zeroshot_2025_tabfm` portfolio.\n",
      "\t\tNote: `zeroshot_2025_tabfm` portfolio requires a CUDA compatible GPU for best performance.\n",
      "\t\tMake sure you have all the relevant dependencies installed: `pip install autogluon.tabular[tabarena]`.\n",
      "\t\tIt is strongly recommended to use a machine with 64+ GB memory and a CUDA compatible GPU with 32+ GB vRAM when using this preset. \n",
      "\t\tThis portfolio will download foundation model weights from HuggingFace during training. Ensure you have an internet connection or have pre-downloaded the weights to use these models.\n",
      "\t\tThis portfolio was meta-learned with TabArena: https://tabarena.ai\n",
      "Using hyperparameters preset: hyperparameters='zeroshot_2025_tabfm'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"C:\\Users\\maz\\dev\\Projects_\\alzheimer\\models\\ft_engineered\"\n",
      "Train Data Rows:    2311\n",
      "Train Data Columns: 67\n",
      "Label Column:       composite_score\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (334, 10, 146.64042, 59.28736)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3884.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.69 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 52 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['Year', 'Gender', 'EducationMother', 'EducationFather']\n",
      "\t\t('float', [])    : 13 | ['delta_hincome', 'delta_SpouseEarnings', 'delta_hinc_assets', 'delta_Marriages', 'delta_Num_ADL', ...]\n",
      "\t\t('int', [])      : 50 | ['PredictionYear', 'changed_HeartAttack', 'changed_Test_Cholestrol', 'changed_Married', 'changed_Test_BloodPress', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['EducationMother', 'EducationFather']\n",
      "\t\t('float', [])     : 13 | ['delta_hincome', 'delta_SpouseEarnings', 'delta_hinc_assets', 'delta_Marriages', 'delta_Num_ADL', ...]\n",
      "\t\t('int', ['bool']) : 52 | ['Year', 'Gender', 'PredictionYear', 'changed_HeartAttack', 'changed_Test_Cholestrol', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t67 features in original data used to generate 67 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (21 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'TABPFNV2': [{'ag_args': {'name_suffix': '_r143', 'priority': -1}, 'average_before_softmax': False, 'classification_model_path': 'tabpfn-v2-classifier-od3j1g5m.ckpt', 'inference_config/FINGERPRINT_FEATURE': False, 'inference_config/OUTLIER_REMOVAL_STD': None, 'inference_config/POLYNOMIAL_FEATURES': 'no', 'inference_config/PREPROCESS_TRANSFORMS': [{'append_original': True, 'categorical_name': 'ordinal_very_common_categories_shuffled', 'global_transformer_name': None, 'name': 'safepower', 'subsample_features': -1}, {'append_original': True, 'categorical_name': 'ordinal_very_common_categories_shuffled', 'global_transformer_name': None, 'name': 'quantile_uni', 'subsample_features': -1}], 'inference_config/REGRESSION_Y_PREPROCESS_TRANSFORMS': [None, 'power'], 'inference_config/SUBSAMPLE_SAMPLES': 0.99, 'model_type': 'single', 'n_ensemble_repeats': 4, 'regression_model_path': 'tabpfn-v2-regressor-wyl4o83o.ckpt', 'softmax_temperature': 0.75}, {'ag_args': {'name_suffix': '_r94', 'priority': -3}, 'average_before_softmax': True, 'classification_model_path': 'tabpfn-v2-classifier-vutqq28w.ckpt', 'inference_config/FINGERPRINT_FEATURE': True, 'inference_config/OUTLIER_REMOVAL_STD': None, 'inference_config/POLYNOMIAL_FEATURES': 'no', 'inference_config/PREPROCESS_TRANSFORMS': [{'append_original': True, 'categorical_name': 'ordinal_very_common_categories_shuffled', 'global_transformer_name': None, 'name': 'quantile_uni', 'subsample_features': 0.99}], 'inference_config/REGRESSION_Y_PREPROCESS_TRANSFORMS': [None], 'inference_config/SUBSAMPLE_SAMPLES': None, 'model_type': 'single', 'n_ensemble_repeats': 4, 'regression_model_path': 'tabpfn-v2-regressor-5wof9ojf.ckpt', 'softmax_temperature': 0.9}, {'ag_args': {'name_suffix': '_r181', 'priority': -4}, 'average_before_softmax': False, 'classification_model_path': 'tabpfn-v2-classifier-llderlii.ckpt', 'inference_config/FINGERPRINT_FEATURE': False, 'inference_config/OUTLIER_REMOVAL_STD': 9.0, 'inference_config/POLYNOMIAL_FEATURES': 50, 'inference_config/PREPROCESS_TRANSFORMS': [{'append_original': True, 'categorical_name': 'onehot', 'global_transformer_name': 'svd', 'name': 'quantile_uni_coarse', 'subsample_features': 0.99}], 'inference_config/REGRESSION_Y_PREPROCESS_TRANSFORMS': ['power'], 'inference_config/SUBSAMPLE_SAMPLES': None, 'model_type': 'single', 'n_ensemble_repeats': 4, 'regression_model_path': 'tabpfn-v2-regressor.ckpt', 'softmax_temperature': 0.95}],\n",
      "\t'GBM': [{'ag_args': {'name_suffix': '_r33', 'priority': -2}, 'bagging_fraction': 0.9625293420216, 'bagging_freq': 1, 'cat_l2': 0.1236875455555, 'cat_smooth': 68.8584757332856, 'extra_trees': False, 'feature_fraction': 0.6189215809382, 'lambda_l1': 0.1641757352921, 'lambda_l2': 0.6937755557881, 'learning_rate': 0.0154031028561, 'max_cat_to_onehot': 17, 'min_data_in_leaf': 1, 'min_data_per_group': 30, 'num_leaves': 68}, {'ag_args': {'name_suffix': '_r21', 'priority': -16}, 'bagging_fraction': 0.7218730663234, 'bagging_freq': 1, 'cat_l2': 0.0296205152578, 'cat_smooth': 0.0010255271303, 'extra_trees': False, 'feature_fraction': 0.4557131604374, 'lambda_l1': 0.5219704038237, 'lambda_l2': 0.1070959487853, 'learning_rate': 0.0055891584996, 'max_cat_to_onehot': 71, 'min_data_in_leaf': 50, 'min_data_per_group': 10, 'num_leaves': 30}, {'ag_args': {'name_suffix': '_r11', 'priority': -19}, 'bagging_fraction': 0.775784726514, 'bagging_freq': 1, 'cat_l2': 0.3888471449178, 'cat_smooth': 0.0057144748021, 'extra_trees': True, 'feature_fraction': 0.7732354787904, 'lambda_l1': 0.2211002452568, 'lambda_l2': 1.1318405980187, 'learning_rate': 0.0090151778542, 'max_cat_to_onehot': 15, 'min_data_in_leaf': 4, 'min_data_per_group': 15, 'num_leaves': 2}],\n",
      "\t'CAT': [{'ag_args': {'priority': -5}}, {'ag_args': {'name_suffix': '_r51', 'priority': -10}, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'colsample_bylevel': 0.8771035272558, 'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.0107286863021, 'leaf_estimation_iterations': 2, 'learning_rate': 0.0058424016622, 'max_bin': 254, 'max_ctr_complexity': 4, 'model_size_reg': 0.1307400355809, 'one_hot_max_size': 23, 'subsample': 0.809527841437}, {'ag_args': {'name_suffix': '_r10', 'priority': -12}, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'colsample_bylevel': 0.8994502668431, 'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.8187025215896, 'leaf_estimation_iterations': 7, 'learning_rate': 0.005177304142, 'max_bin': 254, 'max_ctr_complexity': 4, 'model_size_reg': 0.5247386875068, 'one_hot_max_size': 53, 'subsample': 0.8705228845742}],\n",
      "\t'TABM': [{'ag_args': {'name_suffix': '_r184', 'priority': -6}, 'amp': False, 'arch_type': 'tabm-mini', 'batch_size': 'auto', 'd_block': 864, 'd_embedding': 24, 'dropout': 0.0, 'gradient_clipping_norm': 1.0, 'lr': 0.0019256819924656217, 'n_blocks': 3, 'num_emb_n_bins': 3, 'num_emb_type': 'pwl', 'patience': 16, 'share_training_batches': False, 'tabm_k': 32, 'weight_decay': 0.0}, {'ag_args': {'name_suffix': '_r69', 'priority': -7}, 'amp': False, 'arch_type': 'tabm-mini', 'batch_size': 'auto', 'd_block': 848, 'd_embedding': 28, 'dropout': 0.40215621636031007, 'gradient_clipping_norm': 1.0, 'lr': 0.0010413640454559532, 'n_blocks': 3, 'num_emb_n_bins': 18, 'num_emb_type': 'pwl', 'patience': 16, 'share_training_batches': False, 'tabm_k': 32, 'weight_decay': 0.0}, {'ag_args': {'name_suffix': '_r52', 'priority': -11}, 'amp': False, 'arch_type': 'tabm-mini', 'batch_size': 'auto', 'd_block': 1024, 'd_embedding': 32, 'dropout': 0.0, 'gradient_clipping_norm': 1.0, 'lr': 0.0006297851297842611, 'n_blocks': 4, 'num_emb_n_bins': 22, 'num_emb_type': 'pwl', 'patience': 16, 'share_training_batches': False, 'tabm_k': 32, 'weight_decay': 0.06900108498839816}],\n",
      "\t'TABICL': [{'ag_args': {'priority': -8}}],\n",
      "\t'XGB': [{'ag_args': {'name_suffix': '_r171', 'priority': -9}, 'colsample_bylevel': 0.9213705632288, 'colsample_bynode': 0.6443385965381, 'enable_categorical': True, 'grow_policy': 'lossguide', 'learning_rate': 0.0068171645251, 'max_cat_to_onehot': 8, 'max_depth': 6, 'max_leaves': 10, 'min_child_weight': 0.0507304250576, 'reg_alpha': 4.2446346389037, 'reg_lambda': 1.4800570021253, 'subsample': 0.9656290596647}, {'ag_args': {'name_suffix': '_r40', 'priority': -18}, 'colsample_bylevel': 0.6377491713202, 'colsample_bynode': 0.9237625621103, 'enable_categorical': True, 'grow_policy': 'lossguide', 'learning_rate': 0.0112462621131, 'max_cat_to_onehot': 33, 'max_depth': 10, 'max_leaves': 35, 'min_child_weight': 0.1403464856034, 'reg_alpha': 3.4960653958503, 'reg_lambda': 1.3062320805235, 'subsample': 0.6948898835178}],\n",
      "\t'MITRA': [{'n_estimators': 1, 'fine_tune': True, 'fine_tune_steps': 50, 'ag.num_gpus': 1, 'ag_args': {'priority': -21}}],\n",
      "}\n",
      "Fitting 20 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: TabPFNv2_r143_BAG_L1 ... Training model for up to 3599.65s of the 3599.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\tFailed to import tabpfn! To use the TabPFNv2 model, do: `pip install autogluon.tabular[tabpfn]==1.4.0`.\n",
      "\tWarning: Exception caused TabPFNv2_r143_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tNo module named 'tabpfn'\n",
      "Fitting model: LightGBM_r33_BAG_L1 ... Training model for up to 3599.37s of the 3599.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.93%)\n",
      "\t-47.3897\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.56s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: TabPFNv2_r94_BAG_L1 ... Training model for up to 3564.90s of the 3564.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\tFailed to import tabpfn! To use the TabPFNv2 model, do: `pip install autogluon.tabular[tabpfn]==1.4.0`.\n",
      "\tWarning: Exception caused TabPFNv2_r94_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tNo module named 'tabpfn'\n",
      "Fitting model: TabPFNv2_r181_BAG_L1 ... Training model for up to 3564.63s of the 3564.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\tFailed to import tabpfn! To use the TabPFNv2 model, do: `pip install autogluon.tabular[tabpfn]==1.4.0`.\n",
      "\tWarning: Exception caused TabPFNv2_r181_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tNo module named 'tabpfn'\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3564.42s of the 3564.41s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.64% memory usage per fold, 46.56%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=11.64%)\n",
      "\t-48.1947\t = Validation score   (-root_mean_squared_error)\n",
      "\t251.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: TabM_r184_BAG_L1 ... Training model for up to 3305.93s of the 3305.93s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 43.61% memory usage per fold, 43.61%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=0, memory=43.61%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "\t-47.5162\t = Validation score   (-root_mean_squared_error)\n",
      "\t2627.88s\t = Training   runtime\n",
      "\t4.7s\t = Validation runtime\n",
      "Fitting model: TabM_r69_BAG_L1 ... Training model for up to 671.57s of the 671.57s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 70.12% memory usage per fold, 70.12%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=0, memory=70.12%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "\t-54.1194\t = Validation score   (-root_mean_squared_error)\n",
      "\t429.35s\t = Training   runtime\n",
      "\t3.98s\t = Validation runtime\n",
      "Fitting model: XGBoost_r171_BAG_L1 ... Training model for up to 230.53s of the 230.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.96%)\n",
      "\t-48.5088\t = Validation score   (-root_mean_squared_error)\n",
      "\t144.71s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: CatBoost_r51_BAG_L1 ... Training model for up to 70.07s of the 70.07s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.62% memory usage per fold, 58.49%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=14.62%)\n",
      "\t-50.4994\t = Validation score   (-root_mean_squared_error)\n",
      "\t68.32s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -11.35s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r33_BAG_L1': 0.429, 'TabM_r184_BAG_L1': 0.429, 'CatBoost_BAG_L1': 0.071, 'CatBoost_r51_BAG_L1': 0.071}\n",
      "\t-46.9183\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3611.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 48.2 rows/s (289 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"C:\\Users\\maz\\dev\\Projects_\\alzheimer\\models\\ft_engineered\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x19ba2515e50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the models\n",
    "start_time = time.time()\n",
    "\n",
    "predictor.fit(**fit_args)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = (total_time % 3600) % 60\n",
    "print(f\"Total time: {hours} hours, {minutes} minutes, and {seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985b6cc-882e-4f53-b8cf-9970460c4d99",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c102a-db38-4422-970c-8fe5515fe48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation and Prediction ---\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "# Display the leaderboard to see the performance of all trained models on the validation data\n",
    "# We can also pass the test data to see out-of-sample performance.\n",
    "leaderboard = predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfc08f22-2e75-4bfd-875d-a448f25e7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f55005d-8591-418a-ab4f-bbf4f18f7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_r33_BAG_L1</td>\n",
       "      <td>-45.733922</td>\n",
       "      <td>-47.389724</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-45.833239</td>\n",
       "      <td>-46.918285</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TabM_r184_BAG_L1</td>\n",
       "      <td>-46.419047</td>\n",
       "      <td>-47.516198</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_r171_BAG_L1</td>\n",
       "      <td>-47.111150</td>\n",
       "      <td>-48.508782</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-47.452942</td>\n",
       "      <td>-48.194741</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_r51_BAG_L1</td>\n",
       "      <td>-50.188957</td>\n",
       "      <td>-50.499425</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TabM_r69_BAG_L1</td>\n",
       "      <td>-53.710891</td>\n",
       "      <td>-54.119442</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val              eval_metric  \\\n",
       "0  LightGBM_r33_BAG_L1  -45.733922 -47.389724  root_mean_squared_error   \n",
       "1  WeightedEnsemble_L2  -45.833239 -46.918285  root_mean_squared_error   \n",
       "2     TabM_r184_BAG_L1  -46.419047 -47.516198  root_mean_squared_error   \n",
       "3  XGBoost_r171_BAG_L1  -47.111150 -48.508782  root_mean_squared_error   \n",
       "4      CatBoost_BAG_L1  -47.452942 -48.194741  root_mean_squared_error   \n",
       "5  CatBoost_r51_BAG_L1  -50.188957 -50.499425  root_mean_squared_error   \n",
       "6      TabM_r69_BAG_L1  -53.710891 -54.119442  root_mean_squared_error   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            1       True          1  \n",
       "1            2       True          7  \n",
       "2            1       True          3  \n",
       "3            1       True          5  \n",
       "4            1       True          2  \n",
       "5            1       True          6  \n",
       "6            1       True          4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lb = leaderboard[[\"model\", \"score_test\", \"score_val\", \"eval_metric\", \"stack_level\", \"can_infer\", \"fit_order\"]]\n",
    "# print(leaderboard)\n",
    "# print(df_lb)\n",
    "# leaderboard\n",
    "df_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac5fe7fa-7bd1-4e56-a23f-2a70fdbab1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Ensemble Performance on Test Data\n",
      "**************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>r2</th>\n",
       "      <th>pearsonr</th>\n",
       "      <th>median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.833239</td>\n",
       "      <td>-2100.685791</td>\n",
       "      <td>-35.190224</td>\n",
       "      <td>0.379713</td>\n",
       "      <td>0.61796</td>\n",
       "      <td>-28.570831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_mean_squared_error  mean_squared_error  mean_absolute_error        r2  \\\n",
       "0               -45.833239        -2100.685791           -35.190224  0.379713   \n",
       "\n",
       "   pearsonr  median_absolute_error  \n",
       "0   0.61796             -28.570831  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the final ensemble model on the test data\n",
    "performance_dict = predictor.evaluate(test_data)\n",
    "performance = pd.DataFrame(performance_dict, index=[0])\n",
    "print(\"Final Ensemble Performance on Test Data\")\n",
    "print(\"*\" * 40)\n",
    "# print(performance)\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5afa2e-8c46-4865-ab65-3755fef691fe",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7839292a-100a-43b7-9e81-264f742dded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Making Predictions ---\n"
     ]
    }
   ],
   "source": [
    "# --- Making Predictions ---\n",
    "print(\"\\n--- Making Predictions ---\")\n",
    "# Predict on the test data (you can also use new, unseen data)\n",
    "predictions = predictor.predict(test_data.drop(columns=[label_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9489898d-f4ad-4603-b234-17804f4e62f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Actual vs. Predicted Scores:\n",
      "******************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_score</th>\n",
       "      <th>predicted_score</th>\n",
       "      <th>difference</th>\n",
       "      <th>absolute_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>175</td>\n",
       "      <td>214.911499</td>\n",
       "      <td>-39.911499</td>\n",
       "      <td>39.911499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>129</td>\n",
       "      <td>167.062790</td>\n",
       "      <td>-38.062790</td>\n",
       "      <td>38.062790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>78</td>\n",
       "      <td>119.418396</td>\n",
       "      <td>-41.418396</td>\n",
       "      <td>41.418396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>77</td>\n",
       "      <td>132.670044</td>\n",
       "      <td>-55.670044</td>\n",
       "      <td>55.670044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>140</td>\n",
       "      <td>117.531631</td>\n",
       "      <td>22.468369</td>\n",
       "      <td>22.468369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual_score  predicted_score  difference  absolute_difference\n",
       "471            175       214.911499  -39.911499            39.911499\n",
       "1206           129       167.062790  -38.062790            38.062790\n",
       "2382            78       119.418396  -41.418396            41.418396\n",
       "2013            77       132.670044  -55.670044            55.670044\n",
       "2885           140       117.531631   22.468369            22.468369"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame for a clear comparison\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "results_df = pd.DataFrame({\n",
    "    'actual_score': test_data['composite_score'],\n",
    "    'predicted_score': predictions_df['composite_score']\n",
    "})\n",
    "\n",
    "# --- Calculate the Difference ---\n",
    "# This shows the error. A positive value means the prediction was too low.\n",
    "# A negative value means the prediction was too high.\n",
    "results_df['difference'] = results_df['actual_score'] - results_df['predicted_score']\n",
    "\n",
    "# --- (Optional but Recommended) Calculate the Absolute Difference ---\n",
    "# This shows the magnitude of the error, regardless of direction.\n",
    "results_df['absolute_difference'] = abs(results_df['difference'])\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"Comparison of Actual vs. Predicted Scores:\")\n",
    "print(\"*\" * 42)\n",
    "# print(results_df.head())\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3dbcf6-1b97-4cb0-98eb-43f241f7c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the predictions\n",
    "# print(\"Sample predictions:\")\n",
    "# print(predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da0688-89a6-47f5-9174-49016ec4adbf",
   "metadata": {},
   "source": [
    "**The minus sign is there because the framework is designed to always maximize a score. Since Root Mean Squared Error (RMSE) is an error metric where a lower value is better, the framework negates it.**\n",
    "\n",
    "### Detailed Breakdown\n",
    "\n",
    "- Maximizing vs. Minimizing:\n",
    "    - For metrics like `Accuracy` or `R-squared`, a higher score is better. So, an optimizer's job is to maximize them.\n",
    "    - For metrics like `Root Mean Squared Error` (eval_metric), a lower score is better (an error of 0 is perfect). An optimizer's job is to minimize them.\n",
    "- The Trick: Negating the Error:\n",
    "    - To avoid having to build separate logic for maximizing and minimizing, many `AutoML` frameworks (like `AutoGluon`, which this looks like) use a simple trick: they treat every problem as a maximization problem.\n",
    "    - To do this with an error metric, they simply multiply it by -1.\n",
    "    - Minimizing `RMSE` is the same as maximizing (-RMSE).\n",
    "\n",
    "**Is it Good or Bad?**\n",
    "It is neither good nor bad; it's just a reporting convention. The key is knowing how to interpret it.\n",
    "**How to Interpret the Scores:**\n",
    "\n",
    "    - You should look for the score that is closest to zero.\n",
    "    - A score of -45.8 is better than a score of -53.7.\n",
    "\n",
    "**Look at the leaderboard (df_lb):**\n",
    "\n",
    "- The `WeightedEnsemble_L2` has a score_test of -45.833239.\n",
    "- The `TabM_r69_BAG_L1` has a score_test of -53.710891.\n",
    "  \n",
    "Since -45.8 is a higher number (closer to zero) than -53.7, the WeightedEnsemble_L2 model performed better.\n",
    "\n",
    "**What is the Actual Error?**\n",
    "\n",
    "To get the real, interpretable error metric, just take the positive value.\n",
    "\n",
    "Based on `Final Ensemble Performance` table:\n",
    "\n",
    "- `root_mean_squared_error` is -45.833239.\n",
    "- This means the actual `Root Mean Squared Error` of the model on the test data is `45.833239`.\n",
    "- Similarly, the actual `Mean Absolute Error` is `35.190224`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bf2c3-a680-4f6e-9270-0290ca72523a",
   "metadata": {},
   "source": [
    "#### Clean up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8647c93-5d52-4bbe-b958-68aad2fa35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean up (Optional) ---\n",
    "# You can load the predictor later using:\n",
    "# loaded_predictor = TabularPredictor.load('ag_models_composite_score/')\n",
    "# And then use it to make predictions on new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimer-uv",
   "language": "python",
   "name": "alzheimer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

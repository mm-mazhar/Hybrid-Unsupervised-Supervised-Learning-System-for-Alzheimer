{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b31a50-4d7c-45d6-9b90-cfee3b7eb1f6",
   "metadata": {},
   "source": [
    "### What this demonstrates\n",
    "\n",
    "This code proves we have built a `Smart Diagnostic System`, not just a \"model.\"\n",
    "\n",
    "1. It intelligently profiles the patient first.\n",
    "\n",
    "2. It selects the mathematically superior tool for that specific profile.\n",
    "\n",
    "3. It outputs a precision score.\n",
    "   \n",
    "This is the perfect conclusion to our research project.\n",
    "\n",
    "NOTE: This is for \"Demo\" purpose only. In real we should feed the real test data which model has never seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf0cbf-5145-4d7b-a9c1-130cfb0282d0",
   "metadata": {},
   "source": [
    "### 1. SYSTEM SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f3f724-89e2-4a1f-b485-596ee3805792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference System Initialized.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Path Setup\n",
    "dataset_dir = \"..//dataset//modified\"\n",
    "path_train_clustered = Path(dataset_dir) / \"train_with_clusters.csv\"\n",
    "\n",
    "# Model Paths\n",
    "path_strategy_a = Path(\"..//models//strategyA\") # Specialists\n",
    "path_strategy_b = Path(\"..//models//strategyB\") # Global Meta\n",
    "path_strategy_c = Path(\"..//models//strategyC\") # Oversampled\n",
    "\n",
    "print(\"Inference System Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2a6a1-8ebc-400b-b73c-3144c75f220e",
   "metadata": {},
   "source": [
    "### 2. LOAD & RECONSTRUCT THE ROUTER (K-MEANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fba9377-0965-4f7f-bd75-3132d7e9ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to reconstruct the Router...\n",
      "Routing based on 122 numeric features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marriages_03</th>\n",
       "      <th>Migration_03</th>\n",
       "      <th>ADL_Dress_03</th>\n",
       "      <th>ADL_Walk_03</th>\n",
       "      <th>ADL_Bath_03</th>\n",
       "      <th>ADL_Eat_03</th>\n",
       "      <th>ADL_Bed_03</th>\n",
       "      <th>ADL_Toilet_03</th>\n",
       "      <th>Num_ADL_03</th>\n",
       "      <th>IADL_Money_03</th>\n",
       "      <th>...</th>\n",
       "      <th>SpouseEarnings_12</th>\n",
       "      <th>hincome_12</th>\n",
       "      <th>hinc_business_12</th>\n",
       "      <th>hinc_rent_12</th>\n",
       "      <th>hinc_assets_12</th>\n",
       "      <th>hinc_cap_12</th>\n",
       "      <th>Pension_12</th>\n",
       "      <th>SpousePension_12</th>\n",
       "      <th>AttendReligiousServices_12</th>\n",
       "      <th>SpeaksEnglish_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.023006</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.050613</td>\n",
       "      <td>0.032209</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.222393</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>...</td>\n",
       "      <td>8496.932515</td>\n",
       "      <td>40552.147239</td>\n",
       "      <td>10184.049080</td>\n",
       "      <td>46.012270</td>\n",
       "      <td>343.558282</td>\n",
       "      <td>10552.147239</td>\n",
       "      <td>8496.932515</td>\n",
       "      <td>6595.092025</td>\n",
       "      <td>0.430982</td>\n",
       "      <td>0.009202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.087719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3508.771930</td>\n",
       "      <td>152631.578947</td>\n",
       "      <td>74035.087719</td>\n",
       "      <td>30877.192982</td>\n",
       "      <td>719.298246</td>\n",
       "      <td>105438.596491</td>\n",
       "      <td>12982.456140</td>\n",
       "      <td>6666.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098266</td>\n",
       "      <td>0.121387</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>...</td>\n",
       "      <td>7630.057803</td>\n",
       "      <td>77803.468208</td>\n",
       "      <td>22167.630058</td>\n",
       "      <td>-895.953757</td>\n",
       "      <td>1627.167630</td>\n",
       "      <td>22890.173410</td>\n",
       "      <td>16242.774566</td>\n",
       "      <td>7514.450867</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.031792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978937</td>\n",
       "      <td>0.050150</td>\n",
       "      <td>0.023069</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.015045</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>...</td>\n",
       "      <td>5155.466399</td>\n",
       "      <td>62647.943831</td>\n",
       "      <td>16298.896690</td>\n",
       "      <td>20.060181</td>\n",
       "      <td>1293.881645</td>\n",
       "      <td>17642.928786</td>\n",
       "      <td>9869.608826</td>\n",
       "      <td>16389.167503</td>\n",
       "      <td>0.399198</td>\n",
       "      <td>0.012036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.178230</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.021531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7248.803828</td>\n",
       "      <td>80083.732057</td>\n",
       "      <td>15155.502392</td>\n",
       "      <td>358.851675</td>\n",
       "      <td>241.626794</td>\n",
       "      <td>15741.626794</td>\n",
       "      <td>26973.684211</td>\n",
       "      <td>3911.483254</td>\n",
       "      <td>0.328947</td>\n",
       "      <td>0.059809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Marriages_03  Migration_03  ADL_Dress_03  ADL_Walk_03  ADL_Bath_03  \\\n",
       "cluster                                                                       \n",
       "0            1.023006      0.069018      0.115031     0.050613     0.032209   \n",
       "1            1.087719      0.000000      0.035088     0.017544     0.000000   \n",
       "2            2.098266      0.121387      0.008671     0.005780     0.002890   \n",
       "3            0.978937      0.050150      0.023069     0.009027     0.002006   \n",
       "5            0.980861      0.178230      0.011962     0.007177     0.000000   \n",
       "\n",
       "         ADL_Eat_03  ADL_Bed_03  ADL_Toilet_03  Num_ADL_03  IADL_Money_03  \\\n",
       "cluster                                                                     \n",
       "0          0.012270    0.081288       0.046012    0.222393       0.015337   \n",
       "1          0.000000    0.000000       0.000000    0.017544       0.000000   \n",
       "2          0.005780    0.005780       0.008671    0.028902       0.002890   \n",
       "3          0.002006    0.015045       0.002006    0.030090       0.002006   \n",
       "5          0.000000    0.008373       0.005981    0.021531       0.000000   \n",
       "\n",
       "         ...  SpouseEarnings_12     hincome_12  hinc_business_12  \\\n",
       "cluster  ...                                                       \n",
       "0        ...        8496.932515   40552.147239      10184.049080   \n",
       "1        ...        3508.771930  152631.578947      74035.087719   \n",
       "2        ...        7630.057803   77803.468208      22167.630058   \n",
       "3        ...        5155.466399   62647.943831      16298.896690   \n",
       "5        ...        7248.803828   80083.732057      15155.502392   \n",
       "\n",
       "         hinc_rent_12  hinc_assets_12    hinc_cap_12    Pension_12  \\\n",
       "cluster                                                              \n",
       "0           46.012270      343.558282   10552.147239   8496.932515   \n",
       "1        30877.192982      719.298246  105438.596491  12982.456140   \n",
       "2         -895.953757     1627.167630   22890.173410  16242.774566   \n",
       "3           20.060181     1293.881645   17642.928786   9869.608826   \n",
       "5          358.851675      241.626794   15741.626794  26973.684211   \n",
       "\n",
       "         SpousePension_12  AttendReligiousServices_12  SpeaksEnglish_12  \n",
       "cluster                                                                  \n",
       "0             6595.092025                    0.430982          0.009202  \n",
       "1             6666.666667                    0.333333          0.035088  \n",
       "2             7514.450867                    0.317919          0.031792  \n",
       "3            16389.167503                    0.399198          0.012036  \n",
       "5             3911.483254                    0.328947          0.059809  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router Logic Built: We will match patients to these average profiles.\n"
     ]
    }
   ],
   "source": [
    "# Since we need to route new patients, we need the K-Means model.\n",
    "# If you didn't save it in step C, we can quickly rebuild it using the exact same random_state.\n",
    "\n",
    "print(\"Loading data to reconstruct the Router...\")\n",
    "df = pd.read_csv(path_train_clustered)\n",
    "\n",
    "# 1. Clean Data (Same steps as c_clustering)\n",
    "# We need the numeric/categorical matrix used for clustering (before one-hot)\n",
    "# For simplicity, let's assume we re-run the scaling on the numeric columns used for clustering.\n",
    "# NOTE: In a real deployment, you would load 'kmeans.pkl' and 'scaler.pkl'. \n",
    "# Here we reconstruct them for demonstration.\n",
    "\n",
    "# Filter out the outlier (Cluster 4) to match our training environment\n",
    "df = df[df['cluster'] != 4].copy()\n",
    "\n",
    "# Select features used for clustering (This must match your c_clustering notebook)\n",
    "# Based on your PDF, you used specific columns. Let's infer the data structure needed for K-Means\n",
    "# or simply use the labeled data to \"train\" a Nearest Centroid router.\n",
    "\n",
    "# SIMPLEST ROUTER APPROACH:\n",
    "# We will calculate the \"Average Profile\" (Centroid) of each cluster from the data.\n",
    "# When a new patient arrives, we check which Centroid they are closest to.\n",
    "\n",
    "numeric_cols_for_routing = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "# Remove target and leakage\n",
    "numeric_cols_for_routing = [c for c in numeric_cols_for_routing if c not in ['composite_score', 'cluster', 'Year', 'PredictionYear']]\n",
    "\n",
    "print(f\"Routing based on {len(numeric_cols_for_routing)} numeric features.\")\n",
    "\n",
    "# Calculate Centroids\n",
    "cluster_centroids = df.groupby('cluster')[numeric_cols_for_routing].mean()\n",
    "display(cluster_centroids)\n",
    "\n",
    "print(\"Router Logic Built: We will match patients to these average profiles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7236b-1377-41d8-95fe-0748b93772dd",
   "metadata": {},
   "source": [
    "### 3. LOAD THE SPECIALIST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4248c307-3635-4a56-b77a-e647c7c5fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hybrid Model System...\n",
      " - Loaded Specialist Model A for Cluster 2\n",
      " - Loaded Specialist Model A for Cluster 3\n",
      " - Loaded Specialist Model A for Cluster 5\n",
      " - Loaded Global Model B for Cluster 1 (The Wealthy)\n",
      " - Loaded Oversampled Model C for Cluster 0 (The Frail)\n",
      "\n",
      "All Systems Online.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Hybrid Model System...\")\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Load Strategy A (Specialists) for Clusters 2, 3, 5\n",
    "for c_id in [2, 3, 5]:\n",
    "    path = path_strategy_a / f\"specialist_model_cluster_{c_id}.pkl\"\n",
    "    models[c_id] = joblib.load(path)\n",
    "    print(f\" - Loaded Specialist Model A for Cluster {c_id}\")\n",
    "\n",
    "# Load Strategy B (Global) for Cluster 1 (Wealthy)\n",
    "models[1] = joblib.load(path_strategy_b / \"global_meta_feature_model.pkl\")\n",
    "print(f\" - Loaded Global Model B for Cluster 1 (The Wealthy)\")\n",
    "\n",
    "# Load Strategy C (Oversampled) for Cluster 0 (Frail)\n",
    "models[0] = joblib.load(path_strategy_c / \"strategy_c_oversampled_model.pkl\")\n",
    "print(f\" - Loaded Oversampled Model C for Cluster 0 (The Frail)\")\n",
    "\n",
    "print(\"\\nAll Systems Online.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db5523-a06a-413f-87ba-115f76b6d4e6",
   "metadata": {},
   "source": [
    "### 4. THE INFERENCE ENGINE (Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d771f89d-8c74-4686-9242-1ad2611f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patient_health(new_patient_data):\n",
    "    \"\"\"\n",
    "    input: dict or series containing patient data\n",
    "    output: predicted composite_score\n",
    "    \"\"\"\n",
    "    # 1. Convert to DataFrame\n",
    "    patient_df = pd.DataFrame([new_patient_data])\n",
    "    \n",
    "    # 2. ROUTING (Find the Cluster)\n",
    "    # We calculate distance to the centroids we built in Step 2\n",
    "    # Note: In production, we'd scale this input first. For this demo, we assume raw input matches raw centroids approx.\n",
    "    \n",
    "    distances = {}\n",
    "    for c_id, centroid in cluster_centroids.iterrows():\n",
    "        # Euclidean distance on numeric columns\n",
    "        dist = np.linalg.norm(patient_df[numeric_cols_for_routing].values - centroid.values)\n",
    "        distances[c_id] = dist\n",
    "        \n",
    "    # Pick the closest cluster\n",
    "    assigned_cluster = min(distances, key=distances.get)\n",
    "    \n",
    "    print(f\"\\n--- Processing New Patient ---\")\n",
    "    print(f\"Router: Patient identified as Cluster {assigned_cluster}\")\n",
    "    \n",
    "    # 3. HYBRID LOGIC SWITCH\n",
    "    if assigned_cluster == 0:\n",
    "        print(\"Logic: Applying Strategy C (Optimized for Frailty)...\")\n",
    "        model = models[0]\n",
    "        # Strategy C pipeline expects raw features (minus cluster)\n",
    "        prediction = model.predict(patient_df)[0]\n",
    "        \n",
    "    elif assigned_cluster == 1:\n",
    "        print(\"Logic: Applying Strategy B (Optimized for Small/Wealthy Groups)...\")\n",
    "        model = models[1]\n",
    "        # Strategy B expects 'cluster' column to be present as a feature\n",
    "        patient_df['cluster'] = str(assigned_cluster) \n",
    "        prediction = model.predict(patient_df)[0]\n",
    "        \n",
    "    else: # Clusters 2, 3, 5\n",
    "        print(f\"Logic: Applying Strategy A (Specialist for Cluster {assigned_cluster})...\")\n",
    "        model = models[assigned_cluster]\n",
    "        # Strategy A pipeline expects raw features\n",
    "        prediction = model.predict(patient_df)[0]\n",
    "        \n",
    "    print(f\"✅ PREDICTED COMPOSITE SCORE: {prediction:.2f}\")\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d632fb8-9a65-4de4-a46d-9d9d83e048e7",
   "metadata": {},
   "source": [
    "### 5. DEMO: SIMULATING NEW PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14668de-c0cb-4037-a9e7-acc157d84b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test Case 1]\n",
      "\n",
      "--- Processing New Patient ---\n",
      "Router: Patient identified as Cluster 0\n",
      "Logic: Applying Strategy C (Optimized for Frailty)...\n",
      "✅ PREDICTED COMPOSITE SCORE: 131.36\n",
      "\n",
      "[Test Case 2]\n",
      "\n",
      "--- Processing New Patient ---\n",
      "Router: Patient identified as Cluster 1\n",
      "Logic: Applying Strategy B (Optimized for Small/Wealthy Groups)...\n",
      "✅ PREDICTED COMPOSITE SCORE: 216.41\n",
      "\n",
      "[Test Case 3]\n",
      "\n",
      "--- Processing New Patient ---\n",
      "Router: Patient identified as Cluster 0\n",
      "Logic: Applying Strategy C (Optimized for Frailty)...\n",
      "✅ PREDICTED COMPOSITE SCORE: 109.81\n"
     ]
    }
   ],
   "source": [
    "# Let's pick 3 real examples from our dataset to simulate \"New Patients\"\n",
    "# We pick one from Cluster 0, one from 1, and one from 5.\n",
    "\n",
    "sample_patients = []\n",
    "\n",
    "# Get a sample from Cluster 0 (The Frail)\n",
    "p0 = df[df['cluster'] == 0].iloc[0].drop(['composite_score', 'cluster', 'Year', 'PredictionYear']).to_dict()\n",
    "sample_patients.append(p0)\n",
    "\n",
    "# Get a sample from Cluster 1 (The Wealthy)\n",
    "p1 = df[df['cluster'] == 1].iloc[0].drop(['composite_score', 'cluster', 'Year', 'PredictionYear']).to_dict()\n",
    "sample_patients.append(p1)\n",
    "\n",
    "# Get a sample from Cluster 5 (The Pros)\n",
    "p5 = df[df['cluster'] == 5].iloc[0].drop(['composite_score', 'cluster', 'Year', 'PredictionYear']).to_dict()\n",
    "sample_patients.append(p5)\n",
    "\n",
    "# --- RUN THE SYSTEM ---\n",
    "for i, patient in enumerate(sample_patients):\n",
    "    print(f\"\\n[Test Case {i+1}]\")\n",
    "    pred = predict_patient_health(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f132ea-b660-4e3f-8263-eae991b3406b",
   "metadata": {},
   "source": [
    "### 5. DEMO: SIMULATING \"TRUE\" NEW PATIENTS (Perturbed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a630c601-472d-484c-adb3-4811814ab3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simulating NEW Patients (Data never seen by model) ---\n",
      "\n",
      "[Test Case 1: The Frail Profile]\n",
      "\n",
      "--- Processing New Patient ---\n",
      "Router: Patient identified as Cluster 0\n",
      "Logic: Applying Strategy C (Optimized for Frailty)...\n",
      "✅ PREDICTED COMPOSITE SCORE: 88.14\n",
      "\n",
      "[Test Case 2: The Wealthy Profile]\n",
      "\n",
      "--- Processing New Patient ---\n",
      "Router: Patient identified as Cluster 1\n",
      "Logic: Applying Strategy B (Optimized for Small/Wealthy Groups)...\n",
      "✅ PREDICTED COMPOSITE SCORE: 133.49\n",
      "\n",
      "[Test Case 3: The Professional Profile]\n",
      "\n",
      "--- Processing New Patient ---\n",
      "Router: Patient identified as Cluster 5\n",
      "Logic: Applying Strategy A (Specialist for Cluster 5)...\n",
      "✅ PREDICTED COMPOSITE SCORE: 113.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113.365"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of using exact rows (which the model memorized), we will take a profile\n",
    "# and tweak the numbers. This simulates a \"New Person\" who looks similar \n",
    "# but isn't identical to the training data.\n",
    "\n",
    "print(\"--- Simulating NEW Patients (Data never seen by model) ---\")\n",
    "\n",
    "# --- CASE 1: A Frail Patient (Cluster 0 Profile) ---\n",
    "# We take a base profile and lower their health stats to test Strategy C\n",
    "new_patient_frail = df[df['cluster'] == 0].iloc[5].to_dict() # Pick a random base\n",
    "# Tweak values to make them unique\n",
    "new_patient_frail['Num_Illnesses_03'] += 1  # Sicker\n",
    "new_patient_frail['Num_ADL_03'] = 2.0       # Higher impairment\n",
    "new_patient_frail['hincome_03'] += 500      # Slightly different income\n",
    "# Clean up dict\n",
    "for key in ['composite_score', 'cluster', 'Year', 'PredictionYear']:\n",
    "    new_patient_frail.pop(key, None)\n",
    "\n",
    "print(\"\\n[Test Case 1: The Frail Profile]\")\n",
    "predict_patient_health(new_patient_frail)\n",
    "\n",
    "\n",
    "# --- CASE 2: A Wealthy Patient (Cluster 1 Profile) ---\n",
    "# We test Strategy B\n",
    "new_patient_wealthy = df[df['cluster'] == 1].iloc[5].to_dict()\n",
    "# Tweak values\n",
    "new_patient_wealthy['hincome_03'] = 850000.0 # Huge income change\n",
    "new_patient_wealthy['hinc_cap_03'] += 20000\n",
    "# Clean up dict\n",
    "for key in ['composite_score', 'cluster', 'Year', 'PredictionYear']:\n",
    "    new_patient_wealthy.pop(key, None)\n",
    "\n",
    "print(\"\\n[Test Case 2: The Wealthy Profile]\")\n",
    "predict_patient_health(new_patient_wealthy)\n",
    "\n",
    "\n",
    "# --- CASE 3: An Average Worker (Cluster 5 Profile) ---\n",
    "# We test Strategy A\n",
    "new_patient_pro = df[df['cluster'] == 5].iloc[10].to_dict()\n",
    "# Tweak values\n",
    "new_patient_pro['JobHrsWeekly_03'] = 50.0   # Works more\n",
    "new_patient_pro['Age_03'] = '60-69'         # Changed age group if categorical\n",
    "# Clean up dict\n",
    "for key in ['composite_score', 'cluster', 'Year', 'PredictionYear']:\n",
    "    new_patient_pro.pop(key, None)\n",
    "\n",
    "print(\"\\n[Test Case 3: The Professional Profile]\")\n",
    "predict_patient_health(new_patient_pro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimer-uv",
   "language": "python",
   "name": "alzheimer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
